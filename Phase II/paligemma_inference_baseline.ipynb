{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bdac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "dataset_dir = 'RISCM'\n",
    "images_dir = os.path.join(dataset_dir, 'resized')\n",
    "captions_path = os.path.join(dataset_dir, 'captions.csv')\n",
    "output_csv = os.path.join(dataset_dir, 'paligemma_predictions_test.csv')\n",
    "model_name = \"google/paligemma-3b-pt-224\"\n",
    "hf_token = \" \" # Enter huggingface token for permission\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df = pd.read_csv(captions_path)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "test_df = df[df[\"split\"].str.lower() == \"test\"].reset_index(drop=True)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name, token=hf_token)\n",
    "model = AutoModelForImageTextToText.from_pretrained(model_name, token=hf_token).to(device)\n",
    "\n",
    "def load_image(image_filename):\n",
    "    path = os.path.join(images_dir, image_filename.strip())\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "def generate_caption(img):\n",
    "    input_text = \"<image>Describe this image in detail\\n\"\n",
    "    inputs = processor(text=input_text, images=img, return_tensors=\"pt\", padding=\"longest\", do_convert_rgb=True).to(device)\n",
    "    inputs = inputs.to(dtype=model.dtype)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=64)\n",
    "    return processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Inference on the test set\n",
    "generated_captions = []\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    try:\n",
    "        img = load_image(row['image'])\n",
    "        pred_caption = generate_caption(img)\n",
    "        generated_captions.append(pred_caption)\n",
    "    except Exception as e:\n",
    "        print(f\"Error on image {row['image']}: {e}\")\n",
    "        generated_captions.append(\"\")\n",
    "\n",
    "# Filter the heading and save predictions\n",
    "heading = 'Describe this image in detail\\n\\n'\n",
    "cleaned_captions = [caption.replace(heading, '') for caption in generated_captions]\n",
    "for caption in cleaned_captions:\n",
    "    print(caption)\n",
    "\n",
    "test_df[\"predicted_caption\"] = cleaned_captions\n",
    "test_df.to_csv(output_csv, index=False)\n",
    "print(f\"\\nPredictions saved to: {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
